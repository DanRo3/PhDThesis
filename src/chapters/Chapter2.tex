\chapter{Algoritmos de Estimación de Distribuciones en modelos de lenguaje neuronales}
\label{chap:chapter2}
\subsection{Entrenamiento de las arquitecturas neuronales basados en modelos evolutivos}\label{seq_2}

Para el entrenamiento de estos modelos neuronales se hace uso del algoritmo backpropagation con gradiente descendente estocástico (SDG). Para ello se utiliza la dirección del gradiente para ajustar progresivamente el conjunto de pesos de ambas matrices $W_{1}$ y $W_2$, las cuales son utilizadas para para calcular las capas ocultas de ambos y el vector de salida $u$ que se utiliza para evaluar la función de activación.

Para este problema, se decide elegir un modelo basado en Algoritmos Evolutivos, específicamente el Algoritmos de Estimación de Distribuciones (EDA), para ello son entrenados de forma simultanea ambas matrices. Por lo que un individuo $I$ de la población $P$ estará codificado con un vector de valores continuos de tamaño $L=2(V \times N)$ siendo estos la suma del número de parámetros de ambas matrices. Esto permite interpretar a cada individuo como una configuración de la red neuronal. Así se tiene que $I_{i}=(w_{i,0},w_{i,1},...,w_{i,L-1})$ de $P$. Por lo que $P$ es una matriz, donde cada fila es $I_{i}$, con $0 \le i < \lambda$:

\begin{equation}
P=
\begin{bmatrix}
w_{0,0} & w_{0,1} & \cdots & w_{0,\frac{L}{2}-1} & w_{0,\frac{L}{2}} & w_{0,\frac{L}{2}+1} & \cdots &  w_{0,L-1}\\
w_{1,0} & w_{1,1} & \cdots & w_{1,\frac{L}{2}-1} & w_{1,\frac{L}{2}} & w_{1,\frac{L}{2}+1} & \cdots &  w_{1,L-1}\\	
\vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots \\
w_{\lambda-1,0} & w_{\lambda-1,1} & \cdots & w_{\lambda-1,\frac{L}{2}-1} & w_{\lambda-1,\frac{L}{2}} & w_{\lambda-1,\frac{L}{2}+1} & \cdots &  w_{\lambda-1,L-1}
\end{bmatrix}
\end{equation}
Un individuo $I_{i}$ de $P$ está dividido en dos partes. La primera parte, está comprendida en el intervalo $[0;\frac{L}{2}-1]$, el cual contiene el conjunto de pesos de la matriz $W_{1}$. La otra parte contenida en el intervalo $[\frac{L}{2};L]$, almacena el conjunto de pesos de la matriz $W_{2}$. De esta forma un individuo $I_{i} \in R^{n}$  

Como función de evaluación de la calidad del individuo, se utilizará $E$, por lo que se plantea la siguiente función objetivo dado un individuo $I_{i} \in R^{n}$ y un conjunto de entrenamiento $X$:

\[\arg min_{I_{i}\in R^{n}}E(I_{i},X)\]

Con esto el resultado final de la ejecución de $N$ generaciones, sera la selección del individuo con menor función de pérdida. 

Cabe destacar un elemento importante en la evaluación de la salida de las redes neuronales asociadas a ambos modelos de representación, el cual es el uso de la función softmax jerárquica descrita en \cite{Rong2016} y originalmente aplicada para estos modelos de representación en \cite{Mikolov2013a}. Para ello, se usa en un árbol binario de Huffmann, el cual es estructura no lineal de datos que mantiene un balance de los nodos que representan la información necesaria para evaluar la función, siendo los nodos hojas del árbol las palabras del vocabulario $D$ y los nodos ramas representan unidades internas que pre-calculan parcialmente la función. Por lo que el costo temporal de evaluar la función softmax en la salida $Y$ se reduce a $O(log(V))$. El cálculo de esta función, se realiza mediante la biblioteca Gensim para Python\cite{Landthaler2017}, donde se reutiliza la implementación de Word2Vec basada en la propuesta inicial de T. Mikolov implementada en C++ y descrita en \cite{Mikolov2013,Mikolov2013a}.

\subsection{Modelos probabilístico basados en EDA para el entrenamiento de Word2vec}\label{seq_3}

Haciendo uso de la codificación para un individuo $I \in P$ y la correspondiente función de evaluación de la calidad de un individuo descrita en la sección \ref{seq_2}, se describen cada uno de los algoritmos utilizados para el entrenamiento de los dos modelos de representación usados para implementar Word2Vec. Con esto se implementaron variantes evolutivas para CBOW y Skip-Gram usando EMNA\footnote{Estimation of Multivariate Normal Algorithm}, CUMDA y CMA-ES.

A continuación se describen las implementaciones de cada uno de ellos:

\algsetup{indent=1em}
\begin{algorithm}[H]
	\caption{Algoritmo EDA-EMNA}
	\label{alg1}
	\begin{algorithmic}[1]
		\STATE Inicializar $\sigma \in R$, $x\in R^{n}$
		\WHILE{Criterio de parada no sea alcanzado}
		\FOR{$l = 1..\lambda$}
		\STATE $z_{l}\leftarrow \sigma N_{l}(0,Id)$
		\STATE $x_{l}\leftarrow x + z_{l}$
		\STATE $y_{l}\leftarrow E(x_{l})$
		\ENDFOR
		
		\STATE Ordenar los individuos ascendentemente por su función de evaluación $E$
		\STATE $d(i) \leftarrow z(i)-x$
		\STATE $z^{avg}\leftarrow \frac{1}{\mu}\sum_{i=1}^{\mu}d(i)$
		
		\STATE $\sigma \leftarrow \sqrt{\frac{\sum_{i=1}^{\mu}||z(i)-z^{avg}||^{2}}{\mu N}}$
		\STATE $x\leftarrow x+z^{avg}$
		\ENDWHILE
	\end{algorithmic}
\end{algorithm}

\algsetup{indent=1em}
\begin{algorithm}[H]
	\caption{Algoritmo EDA-CUMDA}
	\label{alg2}
	\begin{algorithmic}[1]
		\STATE Inicializar $\sigma \in R, \hat{x} \in R^{n}$
		\WHILE{Criterio de parada no sea alcanzado}
		\FOR{$l = 1..\lambda$}
		\STATE $z_{l}\leftarrow \sigma N_{l}(O,Id)$
		\STATE $x_{l}\leftarrow \hat{x} + z_{l}$
		\STATE $y_{l}\leftarrow E(x_{l})$
		\ENDFOR
		
		\STATE Ordenar los individuos ascendentemente por su función de evaluación $E$
		\STATE $\hat{x} \leftarrow \frac{1}{\mu}\sum_{i=1}^{\mu}z(i)$
		
		\STATE $\sigma \leftarrow \sqrt{\frac{\sum_{i=1}^{\mu}||z(i)-z^{avg}||^{2}}{\mu N}}$
		
		\ENDWHILE
	\end{algorithmic}
\end{algorithm}

Los algoritmos anteriormente descritos, siguen una implementación similar. En el caso del EMNA, se actualiza el centroide a partir de los valores de la media calculada del conjunto intermedio de tamaño $\mu$ y $\sigma$ representa la desviación estándar. Por otra parte, $\lambda$ indica la cantidad de individuos o puntos que representa una configuración de pesos de la red neuronal asociada a un determinado modelo de representación. Por otra parte la variable $x_{l}$ representa el l-ésimo individuo de la población $P$ de tamaño $\lambda$.

\algsetup{indent=1em}
\begin{algorithm}[H]
	\caption{Algoritmo EDA-CMA-ES}
	\label{alg3}
	\begin{algorithmic}[1]
		\STATE Establecer los parámetros $w_{i=1..\lambda}$, $c_{\sigma},d_{\sigma},c_{c},c_{1}$ y $c_{\mu}$ según como se describe en \cite{Hansen2016}
		\STATE Inicializar $p_{0}$,$p_{c}=0$,$g=0$ y matriz de covarianza $C=I$
		\WHILE{Criterio de parada no sea alcanzado}
		\FOR{$k = 1..\lambda$}
		\STATE $z_{k} ~ N(0,I) $
		\STATE $y_{k} \leftarrow BD_{zk} ~ N(0,C) $
		\STATE $x_{k} \leftarrow m +\mu y_{k} ~N(m,\mu^{2}C) $
		\ENDFOR
		
		Selección y recombinación: 
		\STATE $\qquad \langle y_{w} \rangle=\sum_{i=1}^{\mu}w_{i}y_{i:\lambda}$
		\IF{$c_{m}=1$}
		\STATE $\qquad m\leftarrow \sum_{i=1}^{\mu}w_{i}x_{i:\lambda}$
		\ELSE
		\STATE $\qquad m\leftarrow m+c_{m}\sigma\langle y_{w} \rangle$
		\ENDIF
		
		Controlar el tamaño del paso:
		\STATE $\qquad p_{\sigma}\leftarrow (1-c_{\sigma})p_{\sigma}+\sqrt{c_{\sigma}(2-c_{\sigma})\mu_{eff}}C^{-\frac{1}{2}}\langle y_{w} \rangle$
		
		\STATE $\qquad \sigma \leftarrow \sigma \exp(\frac{c_{\sigma}}{d_{\sigma}}(\frac{||p_{\sigma}||}{E||N(0,I)||}-1))$
		Adaptación de la matriz de covarianza:
		\STATE $\qquad p_{c} \leftarrow (1-c_{c})p_{c}+h_{\sigma}\sqrt{c_{c}(2-c_{c})\mu_{eff}}C^{\frac{1}{2}}\langle y_{w} \rangle$
		
		\STATE \IF{$w_{i}\le 0$}
		\STATE $\qquad w^{o}_{i} = w_{i} \times 1 $
		\ELSE
		\STATE $\qquad w^{o}_{i} = w_{i} \times \frac{n}{||C^{-\frac{1}{2}}y_{i:\lambda}||^{2}} $
		\ENDIF
		
		$\qquad C\leftarrow (1+\underset{generalmente\,igual\,a\, 0}{\underbrace{c_{1}\delta h_{\sigma}-c_{1}-c_{\mu}\sum w_{j}}})C + c_{1}p_{c}{p_{c}}^T+ c_{\mu}\sum_{i=1}^{\lambda}w^{o}_{i}y_{i:\lambda}y_{i:\lambda}^T$
		
		\ENDWHILE
	\end{algorithmic}
\end{algorithm}	

En este algoritmo (\ref{alg3}), $BD$ son el resultado de descomponer la matriz de covarianza $C=BD^{2}B^T$. Cada columna de $B$ es una base ortonormal de vectores propios. Por otra parte, los elementos de la diagonal principal de la matriz diagonal $D$ son las raíces cuadradas de los correspondientes valores valores propios positivos. Cabe destacar que $C^{-\frac{1}{2}}= BD^{-1}B^T$~\cite{Hansen2016}.

Se cumple además que $\sum_{i=1}^{\mu}w_{i}=1, w_{i}>0$ para $i=1..\mu$. $x_{i:\lambda}\in R^{n}$ representa el i-ésimo mejor individuo, para este caso, la mejor red neuronal que logra con el conjunto de entrenamiento el menor valor de la función objetivo $E$. $y_{i:\lambda}= (x_{i:\lambda}-m)/\sigma$. Con lo anterior, y tal como se observa en \ref{alg3} $\langle y_{w} \rangle$ se calcula a partir de los datos anteriores y representa el paso de la distribución de la media sin tener en cuenta el tamaño del paso dado por $\sigma$. Se debe conocer que $\mu$ representa la cantidad de pesos $w_{i}$ con valor positivo, además $\mu_{eff}= (\sum_{i=1}^{\mu}w_{i}^{2})^{-1}$ ~\cite{Hansen2016}.

Finalmente se tiene que:
\[E||N(0,I)||=\sqrt{2}\frac{\Gamma(\frac{n+1}{2})}{\Gamma(\frac{n}{2})}\approx \sqrt{n}(1-\frac{1}{4n}-\frac{1}{21n^{2}})\]


\[h_{\sigma}=\begin{cases}
1\,si\,\frac{||p_{\sigma}||}{\sqrt{1-(1-c_{\sigma})^{2(g+1)}}}< (1.4 + \frac{2}{n+1})E||N(0,I)||\\
0\,en\,otro\,caso\,\\
\end{cases}
\]

Así $\delta h_{\sigma} = (1-h_{\sigma})c_{c}(2-c_{c}) \le1$
